{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79018e7d",
   "metadata": {},
   "source": [
    "# Бустинговые алгоритмы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514d74af",
   "metadata": {},
   "source": [
    "## Суть бустинговых алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b82380",
   "metadata": {},
   "source": [
    "История бустинга началась с вопроса о том, можно ли из большого количества относительно слабых и простых моделей получить одну сильную (Кернс и Вэлиант, 1988-1989 гг.). Под слабыми моделями мы подразумеваем не только небольшие и \"слабые\" модели вроде деревьев решений в противовес более \"сильным\" моделям, например, случайному лесу. В нашем случае слабыми моделями могут быть и произвольные алгоритмы машинного обучения, точность которых может быть лишь немногим выше случайного угадывания.\n",
    "\n",
    "Утвердительный математический ответ на этот вопрос нашелся довольно быстро, что само по себе было важным теоретическим результатом для машинного обучения и статистики (статья Роберта Шапире, 1990 год). Однако, потребовалось несколько лет до появления первых работоспособных алгоритмов. Их общий подход заключался в построении линейной комбинации простых моделей (базовых алгоритмов) путем перевзвешивания входных данных. *Каждая последующая модель строилась таким образом, чтобы придавать больший вес и предпочтение ранее некорректно предсказанным наблюдениям*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56087a33",
   "metadata": {},
   "source": [
    "Таким образом, общий принцип работы бустинговых алгоритмов заключается в следующем: **строим серию не особо точных алгоритмов и обучаем их на ошибках друг друга**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316e2596",
   "metadata": {},
   "source": [
    "![title](boosting_01.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2d1c65",
   "metadata": {},
   "source": [
    "***Гипотеза о бустинге*** — может служить некоторым определением бустинговых алгоритмов. Предположим, мы располагаем *слабым обучением*, то есть у нас есть некоторый алгоритм обучения, выдающий нам гипотезу, эффективность которой лишь слегка лучше случайного гадания. Встает вопрос: вытекает ли из существования данного алгоритма слабого обучения существование эффективного алгоритма, который даёт гипотезу произвольной точности (то есть *сильное обучение*). Алгоритмы, которые получают быстро такую гипотезу, становятся известны как \"бустинг\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e49797",
   "metadata": {},
   "source": [
    "## Работа бустингового алгоритма на примере дерева решений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07492d81",
   "metadata": {},
   "source": [
    "Рассмотрим работу бустингового алгоритма на следующем примере. Допустим, у нас есть данные по миллиону музыкальных клипов на Ютубе. По каждому из клипов есть 100 критериев, например:\n",
    "<br>☆ длится ли клип дольше трёх минут,\n",
    "<br>☆ есть ли там прямая бочка,\n",
    "<br>☆ этот трек в жанре «хип-хоп» или нет,\n",
    "<br>☆ выпустил ли клип популярный лейбл,\n",
    "<br>☆ записан ли клип во дворе на мобильный телефон,\n",
    "<br>…\n",
    "<br>Также у нас есть данные о том, набрал ли клип больше миллиона просмотров. Мы хотим научиться предсказывать этот критерий — для определённости назовём его популярностью. Таким образом, мы хотим получить некий алгоритм, которому на вход подаётся 100 критериев клипа в формате да/нет, а на выходе он говорит: «Этому клипу суждено стать популярным»."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eabf594",
   "metadata": {},
   "source": [
    "![title](boosting_02.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff324e8",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3a521a",
   "metadata": {},
   "source": [
    "Пусть самая сильная связь с итоговой популярностью у критерия «Выпустил ли клип популярный лейбл», а критерий «Длится ли клип дольше трёх минут» лучше других предсказывает популярность клипов популярного лейбла. Тогда они ставятся в вершины соответствующих веток:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cd1e59",
   "metadata": {},
   "source": [
    "![title](boosting_03.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4bc40b",
   "metadata": {},
   "source": [
    "В ходе дальнейшего анализа получим итоговое дерево решений:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cadcd5",
   "metadata": {},
   "source": [
    "![title](boosting_04.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e9867",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbfdd98",
   "metadata": {},
   "source": [
    "Возьмём случайную выборку из наших исходных данных, например, 10 000 клипов, и применим к ним случайный набор критериев, например, какие-нибудь 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d77e4e",
   "metadata": {},
   "source": [
    "![title](boosting_05.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b071eab2",
   "metadata": {},
   "source": [
    "И построим на каждой такой выборке более простые деревья — получим модель случайного леса. Теперь запустим клип, которого не было в обучающей выборке. Каждое дерево выдаст свой вердикт, станет ли он популярным — «да» или «нет». Три за, один против — клип ждёт успех. Наверное."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64468ec",
   "metadata": {},
   "source": [
    "![title](boosting_06.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b41c8",
   "metadata": {},
   "source": [
    "### Неслучайный лес — бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a60b65f",
   "metadata": {},
   "source": [
    "Теперь построим похожий лес, но набор данных будет неслучайным. Первое дерево мы построим так же, как и раньше, на случайных данных и случайных критериях. А потом прогоним через это дерево контрольную выборку: другие клипы, по которым у нас есть все данные, но которые не участвуют в обучении. Посмотрим, где дерево ошиблось (первое дерево может давать много ошибок).\n",
    "Теперь создадим следующее дерево. Наша задача — сделать дерево, которое исправит ошибки предыдущего, для этого мы учим дерево исправлять ошибки предшественника:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43711443",
   "metadata": {},
   "source": [
    "![title](boosting_07.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6220ee5",
   "metadata": {},
   "source": [
    "Новое дерево наделает своих ошибок. Делаем третье, которое их исправит. Потом четвёртое. И так далее. Создаём такие деревья, пока не достигнем желаемой точности или пока точность не начнёт падать из-за переобучения. В итоге получаем много деревьев, каждое из которых не очень сильное. Но вместе они складываются в лес, который даёт хорошую точность. Это и есть Бустинг!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4dd1fb",
   "metadata": {},
   "source": [
    "## Алгоритмы бустинга"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1327d19d",
   "metadata": {},
   "source": [
    "### Вспомогательная информация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c1e3db",
   "metadata": {},
   "source": [
    "#### Определения и понятия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71678dd1",
   "metadata": {},
   "source": [
    "Бустинг - это класс методов машинного обучения, основанный на идее, что комбинация простых классификаторов (полученных слабым учеником) может работать лучше, чем любой из простых классификаторов. *Слабый ученик* - это алгоритм обучения, способный производить слабые классификаторы с вероятностью ошибки строго (но незначительно) меньше случайного угадывания (0.5, в двоичном случае). С другой стороны, *сильный ученик* способен (учитывая достаточное количество обучающих данных) давать сильные классификаторы с произвольно малой вероятностью ошибки.\n",
    "<br>Ансамбль классификаторов - это классификатор, построенный на некой комбинации слабых учеников. Стратегия бустинга состоит в том, чтобы обучить много слабых классификаторов и каким-то образом объединить их, вместо того, чтобы пытаться получить один сильный классификатор."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edb7ace",
   "metadata": {},
   "source": [
    "Пусть\n",
    "<br><center>$H_{m}: \\mathfrak{X}\\rightarrow\\left\\{-1,+1\\right\\}$ - $m$-ый слабый бинарный классификатор (для $m=1,...,M$),</center>\n",
    "<br><center>$x \\in \\mathfrak{X}$ - некоторый входной шаблон для классификации.</center>\n",
    "<br>Существует много способов объединить полученную совокупность $\\left\\{H_{m}\\right\\}_{m=1}^M$ в единый прогноз класса. Например, если мы предположим, что классификаторы ошибаются независимо друг от друга, то комбинация большинства голосов должна давать более низкую вероятность ошибки, чем любой из отдельных классификаторов. Тогда, если взять взвешенную линейную комбинацию выходов слабых классификаторов, то функция прогнозирования ансамбля $H:\\mathfrak{X}→\\left\\{−1,+1\\right\\}$ задается следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43cd83a",
   "metadata": {},
   "source": [
    "$$H\\left(x\\right)=\\textrm{sign}\\left(\\sum_{m=1}^M\\alpha_{m}H_{m}\\left(x\\right)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c0ffda",
   "metadata": {},
   "source": [
    "где $\\alpha_{1}, \\alpha_{2}, \\alpha_{M}$ - набор весов (использование простого большинства голосов получается, если все веса равны между собой)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a30d8",
   "metadata": {},
   "source": [
    "По сути, бустинг состоит в многократном использовании слабых алгоритмов обучения на разно взвешенных версиях обучающих данных. Вес каждого метода на каждом раунде алгоритма зависит от точности предыдущих классификаторов, что позволяет алгоритму сосредоточить своё внимание на те примеры, которые все ещё неправильно классифицированы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909daa5",
   "metadata": {},
   "source": [
    "![title](boosting_08.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5980e010",
   "metadata": {},
   "source": [
    "#### Пример: бустинг линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be75984",
   "metadata": {},
   "source": [
    "В качестве иллюстрации - простой пример бустингового алгоритма линейной регрессии для множества $(x_i,y_i)$, $i=1,...,N$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67177c6a",
   "metadata": {},
   "source": [
    "Алгоритм имеет следующий вид:\n",
    "1. Инициализация весов $\\omega^{(1)}_i=\\frac{1}{N},i\\in\\{1,...,N\\}$ и $m=1$.\n",
    "2. Пока $m\\leq M$, выполняем следующий цикл:\n",
    "<br>    ◉ Используя веса $\\omega_i^{(1)}$, методом наименьших квадратов построим линейную регрессию и найдем приближенные значения $\\tilde{y}_i^{(m)}=a^{(m)}+b^{(m)}x_i$.\n",
    "<br>    ◉ Для каждого $i = 1, ..., N$ обновим вес $\\nu^{(m)}_i=(y_i-\\tilde{y}_i^{(m)})$.\n",
    "<br>    ◉ Перенормируем веса, для чего вычислим $S_m=\\sum_{j=1}^N\\nu^{(m)}_j$ и для $i = 1, ..., N$  $     \\omega^{(m+1)}_i=\\frac{\\nu^{(m)}_i}{S_m}$.\n",
    "<br>    ◉ Увеличим счетчик итераций: $m = m + 1$.\n",
    "3. Заканчиваем цикл и в результате получаем прогноз:\n",
    "$$Y_i=\\frac{\\sum_{m=1}^M\\omega_i^{(m)}(x_i)\\tilde{y}^{(m)}_i}{\\sum_{m=1}^M\\omega_i^{(m)}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08d212c",
   "metadata": {},
   "source": [
    "### Классический алгоритм Шапире"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a57de36",
   "metadata": {},
   "source": [
    "**Ввод.** Исходные данные: выборка размером $N$: $Z = \\{z_1, z_2, ..., z_N\\}$, где $z_i = (x_i, y_i)$, $x_i\\in \\mathfrak{X}$ и $y_i\\in \\{-1,+1\\}$.\n",
    "<br>**Вывод.** Классификатор $H:\\mathfrak{X}\\to \\{-1,+1\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb6c95",
   "metadata": {},
   "source": [
    "Алгоритм имеет следующие пункты:\n",
    "<br>*✔️* Произвольно выбрать без замены $L_1 \\lt N$ выборок из $Z$ и получить $Z^*_1$.\n",
    "<br>*✔️* Используя слабого ученика для $Z^*_1$, получим классификатор $H_1$.\n",
    "<br>*✔️* Выберем $L_2 \\lt N$ выборок из $Z$, причем половиной выборок будут данные, неправильно классифицированные по $H_1$, чтобы получить $Z^*_2$.\n",
    "<br>*✔️* Используя слабого ученика из $Z^*_2$, получим классификатор $H_2$.\n",
    "<br>*✔️* Выберем все образцы из $Z$, на которых $H_1$ и $H_2$ не совпадают, получая $Z^*_3$.\n",
    "<br>*✔️* Используя слабого ученика на $Z^*_3$, получим классификатор $H_3$.\n",
    "<br>*✔️* И, наконец, получим окончательный классификатор большинством голосов: $H(x)=\\textrm{sign} \\left(\\sum_{b=1}^3H_b(x)\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c77327d",
   "metadata": {},
   "source": [
    "![title](boosting_09.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5860d7a",
   "metadata": {},
   "source": [
    "Как видно из алгоритма Шапире, обучающий набор случайным образом делится без замены на три множества, $Z^*_1$, $Z^*_2$ и $Z^*_3$. Если при определении принадлежности элемента первые два классификатора ($H_1$ и $H_2$) согласны с меткой класса, то для данного элемента это решение является окончательным. Множество примеров, по которым они не согласны, определяет множество $Z^*_3$, которое и используется для обучения $H_3$. Шапире показал, что этот метод обучения позволяет построить сильный классификатор. В дальнейшем, опираясь на идеи Шапире, Фрейнд предложил новый алгоритм, который значительно эффективней первоначального."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad249fbe",
   "metadata": {},
   "source": [
    "### Алгоритм AdaBoost (для бинарной классификации)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c023b33",
   "metadata": {},
   "source": [
    "После того, как каждый из авторов (Фрейнд и Шапире) предложил свою идею усиления ансамблей алгоритмов классификации (бустинг), в 1996 году появилась их совместная работа, посвященная адапивному алгоритму бустинга, так наываемому **AdaBoost**. Ключевая идея AdaBoost состоит в использовании ***взвешенных версий тех же данных вместо их случайных подвыборок***. При этом один и тот же обучающий (тренировочный) набор используется большое число раз. AdaBoost является алгоритмом адаптивного бустинга в том смысле, что каждый следующий классификатор строится по объектам, которые плохо классифицируются предыдущими классификаторами.\n",
    "<br><br>AdaBoost вызывает слабый классификатор в цикле. После каждого вызова обновляется распределение весов, которые отвечают важности каждого из объектов обучающего множества для классификации. На каждой итерации веса каждого неверно классифицированного объекта возрастают, таким образом новый классификатор «фокусирует своё внимание» на этих объектах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7023039a",
   "metadata": {},
   "source": [
    "**Ввод.** Исходные данные: выборка размером $N$: $Z = \\{z_1, z_2, ..., z_N\\}$, где $z_i = (x_i, y_i)$, $x_i\\in \\mathfrak{X}$ и $y_i\\in \\{-1,+1\\}$, $М$ - максимальное количество классификаторов.\n",
    "<br>**Вывод.** Классификатор $H:\\mathfrak{X}\\to \\{-1,+1\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44919c3",
   "metadata": {},
   "source": [
    "Алгоритм имеет следующий вид:\n",
    "1. Инициализация весов $\\omega^{(1)}_i=\\frac{1}{N},i\\in\\{1,...,N\\}$ и $m=1$.\n",
    "2. Пока $m\\leq M$, выполняем следующий цикл:\n",
    "<br>    ◉ Применяя слабый классификатор к множеству $Z$ и используя веса $\\omega^{(m)}_i$, получем классификатор $H_m:\\mathfrak{X}\\to \\{-1,+1\\}$.\n",
    "<br>    ◉ Вычислим взвешенную ошибку данного классификатора: $\\varepsilon_m =\\sum_{i=1}^N\\omega^{(m)}_ih(-y_iH_m(x_i))$.\n",
    "<br>*Примечание:* Функция $h: R \\to \\{0, 1\\}$ назывется ступенькой Хевисайда и определяется следующим образом:\n",
    "<br><br>$$h(x)=\\left\\{\n",
    "  \\begin{array}{ll}\n",
    "    1, & \\hbox{ если }x\\ge 0 \\\\\n",
    "    0, & \\hbox{ если }x\\lt 0.\n",
    "  \\end{array}\n",
    "\\right.$$\n",
    "<br>Следовательно, так как и $y_i$, и $H_m(x_i)$ принимают значения из {−1, + 1}, имеем $h (−y_i H_m (x_i)) = 1$, если $y_i\\ne H_m(x_i)$, и $h (−y_i H_m (x_i)) = 0$ в случае $y_i= H_m(x_i)$. Соответственно, $\\varepsilon_m$ представляет собой взвешенную ошибку $m$-го классификатора.\n",
    "<br>    ◉ Найдем вес слабого классификатора $\\alpha_m=\\frac{1}{2}\\ln\\frac{1-\\varepsilon_m}{\\varepsilon_m}$. Вес положителен для любого классификатора с точностью выше 50%. Чем больше вес, тем точнее классификатор. Вес становится отрицательным, когда точность падает ниже 50%. Предсказания можно объединять, инвертируя знак. Таким образом, классификатор с точностью в 40% можно преобразовать в классификатор с точностью в 60%. Так он будет вносить вклад в итоговое предсказание, даже если он работал хуже, чем случайное угадывание. Однако окончательный результат никак не изменится под влиянием классификатора, точность которого равна 50%.\n",
    "<br>    ◉ Для каждого $i = 1, ..., N$ обновим вес $\\nu^{(m)}_i=\\omega^{(m)}_i\\exp\\left(-\\alpha_my_iH_m(x_i)\\right)$. Экспонента в числителе всегда будет больше 1 в случае неверной классификации из классификатора с положительным весом. После итерации вес неверно классифицированных объектов возрастет. Классификаторы с отрицательным весом поведут себя аналогичным образом. Здесь есть разница в инверсии знака: правильная классификация станет неправильной. Окончательный прогноз можно рассчитать путем учета вклада каждого классификатора и вычисления суммы их взвешенных прогнозов.\n",
    "<br>    ◉ Перенормируем веса, для чего вычислим $S_m=\\sum_{j=1}^N\\nu^{(m)}_j$ и для $i = 1, ..., N, \\omega^{(m+1)}_i=\\frac{\\nu^{(m)}_i}{S_m}$.\n",
    "<br>    ◉ Увеличим счетчик итераций: $m = m + 1$.\n",
    "3. Заканчиваем цикл и получаем результирующий классификатор: $H(x)=\\mathrm{sign}\\left(\\sum_{j=1}^M\\alpha_jH_j(x)\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75df1e3",
   "metadata": {},
   "source": [
    "Как происходит выбор базового алгоритма классификатора? Чтобы понять это, рассмотрим стандартный функционал качества алгоритма классификации, который и определяет взвешенную ошибку произвольного классификатора $H^*_m$: $Q\\left(H^*_m, \\omega^{(m)}_1, ..., \\omega^{(m)}_N\\right)=\\sum_{i=1}^N\\omega^{(m)}_ih(-y_iH_m^*(x_i))$. Так вот, очередной классификатор $H_m$ определяется из условия минимизации взвешенной ошибки классификации: $$H_m=\\DeclareMathOperator*\\argmin{arg\\,min}\\argmin_{H^*_m}Q\\left(H^*_m, \\omega^{(m)}_1, ..., \\omega^{(m)}_N\\right).$$При этом при вычислении взвешенной ошибки уже учтены новые веса, которые участвуют в поиске нового классификатора, и именно данные с большими весами и составляют существенную часть взвешенной ошибки, которая минимизируется при поиске классификатора."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a702a2f",
   "metadata": {},
   "source": [
    "По сути, AdaBoost является жадным алгоритмом, который создает сильный классификатор путем оптимизации весов и добавления одного слабого классификатора за раз."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e144a1",
   "metadata": {},
   "source": [
    "#### Иллюстрация работы алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e8da8",
   "metadata": {},
   "source": [
    "![title](boosting_10.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b80a407",
   "metadata": {},
   "source": [
    "**Шаг 1.** На первом шаге присваиваем равные веса каждой точке данных и применяем линейный классификатор с целью разделения точек на множества точек с \"плюсами\" и, соответственно, с \"минусами\". Первый классфикатор (h1) сгенерировал вертикальную линию с левой стороны, разделяя точки данных. Как видим, эта вертикальная линия неправильно предсказала три значения \"+\" (плюс). В таком случае назначим более высокие веса этим трем точкам \"+\" (плюс) и применим другой классификатор. На приведенной иллюстрации это соотносится с размером соответствующей точки, то есть, размер трех неправильно предсказанных точек \"+\" (плюс) больше по сравнению с остальными точками данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6827c3fe",
   "metadata": {},
   "source": [
    "**Шаг 2.** Второй классификатор (h2) попытается предсказать эти крупные точки правильно. Теперь вертикальная линия (h2) с правой стороны поля правильно классифицировала три до этого неправильно классифицированных точки \"+\" (плюс). Но опять же, это вызвало ошибки полученной классификации. На этот раз это три точки \"-\" (минус). Опять же, назначим более высокий вес на эти три точки \"-\" (минус) и применим еще один классификатор."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575b265",
   "metadata": {},
   "source": [
    "**Шаг 3.** Третий классификатор (h3) применяется для правильного прогнозирования этих ошибочно классифицированных наблюдений. На этот раз горизонтальная линия генерируется для классификации \"+\" (плюс) и \"-\" (минус) на основе более высокого веса неправильно классифицированных наблюдений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b697d",
   "metadata": {},
   "source": [
    "**Шаг 4.** Теперь, когда процесс разделения классов прошел успешно, остается объединить методы h1, h2 и h3, чтобы сформировать сильный прогноз, имеющий более сложное правило по сравнению с каждым индивидуальным слабым классификатором."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ecefa8",
   "metadata": {},
   "source": [
    "#### Гиперпараметры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac38e00c",
   "metadata": {},
   "source": [
    "**base_estimator**: определяет базовый алгоритм, в качестве базового алгоритма по умолчанию выступает DecisionTreeClassifier, который инициализируется с max_depth=1, для классификации и DecisionTreeRegressor, который инициализируется с max_depth=3.\n",
    "<br>**n_estimators**: определяет количество базовых алгоритмов; по умолчанию - 10, но для улучшения реализации их можно увеличить.\n",
    "<br>**learning_rate**: коэффициент скорости обучения - параметр, отвечающий за то, насколько изменяются веса.\n",
    "<br>**max_depth**: максимальная глубина каждой модели.\n",
    "<br>**n_jobs**: параметр, показывающий, сколько ядер процессора можно использовать для процесса обучения. “-1” значит, что ограничения нет.\n",
    "<br>**random_state**: делает ответ модели повторимым. Модель всегда будет давать один и тот же ответ на одних и тех же данных и параметрах при совпадении значения этого параметра.\n",
    "<br>**loss** *{‘linear’, ‘square’, ‘exponential’}*: определяет функцию потерь, используемую при обновлении весов после каждой итерации. Только для задач регрессии. По умолчанию - linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ec98e7",
   "metadata": {},
   "source": [
    "#### Достоинства"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d3f58",
   "metadata": {},
   "source": [
    "**⌘** Хорошая обобщающая способность. В реальных задачах (не всегда, но часто) удаётся строить композиции, превосходящие по качеству базовые алгоритмы. Обобщающая способность может улучшаться (в некоторых задачах) по мере увеличения числа базовых алгоритмов.\n",
    "<br>**⌘** Простота реализации.\n",
    "<br>**⌘** Собственные временный расходы бустинга невелики. Время построения всей композиции практически полностью определяется временем обучения базовых алгоритмов.\n",
    "<br>**⌘** Возможность идентифицировать объекты, являющиеся шумовыми выбросами. После построения некоторого количества базовых алгоритмов имеет смысл проанализировать распределение весов объектов. Объекты с наибольшими весами, скорее всего, являются шумовыми выбросами, которые стоит исключить из выборки, после чего начать построение композиции заново. Вообще, бустинг можно использовать как универсальный метод фильтрации выбросов перед применением любого другого метода классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d7e77",
   "metadata": {},
   "source": [
    "#### Недостатки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab908d68",
   "metadata": {},
   "source": [
    "**⌘** AdaBoost склонен к переобучению при наличии значительного уровня шума в данных. Экспоненциальная функция потерь $E\\left(z\\right)=e^{-z}$ слишком сильно увеличивает веса наиболее трудных объектов, на которых ошибаются многие базовые алгоритмы. Однако именно эти объекты чаще всего оказываются шумовыми выбросами. В результате AdaBoost начинает настраиваться на шум, что ведёт к переобучению. Проблема решается путём удаления выбросов или применения менее агрессивных функций потерь (что может быть реализовано в алгоритме градиентного бустинга).\n",
    "<br>**⌘** AdaBoost требует достаточно больших обучающих выборок. Другие методы линейной коррекции, в частности, бэггинг, способны строить алгоритмы сопоставимого качества по меньшим выборкам данных.\n",
    "<br>**⌘** Жадная стратегия последовательного добавления приводит к построению неоптимального набора базовых алгоритмов. Для улучшения композиции можно периодически возвращаться к ранее построенным алгоритмам и обучать их заново. Для улучшения коэффициентов можно оптимизировать их ещё раз по окончании процесса бустинга с помощью какого-нибудь стандартного метода построения линейной разделяющей поверхности. Для этой цели рекомендуется использовать SVM (машины опорных векторов).\n",
    "<br>**⌘** Бустинг может приводить к построению громоздких композиций, состоящих из сотен алгоритмов. Такие композиции требуют больших объёмов памяти для хранения базовых алгоритмов и существенных затрат времени на вычисление классификаций. Также большим недостатком этого алгоритма можно считать то, что его нельзя распараллелить, поскольку каждый из предикторов может быть обучен лишь только после окончания обучения предыдущего."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf02064",
   "metadata": {},
   "source": [
    "#### Пример использования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3251d778",
   "metadata": {},
   "source": [
    "##### Считываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c26ca017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Считываем тренировочные данные\n",
    "train = pd.read_csv(\"train_1.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab683106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28315</td>\n",
       "      <td>Male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>108.68</td>\n",
       "      <td>32.7</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15104</td>\n",
       "      <td>Female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>88.79</td>\n",
       "      <td>24.9</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26604</td>\n",
       "      <td>Female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>107.82</td>\n",
       "      <td>26.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27916</td>\n",
       "      <td>Male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>97.39</td>\n",
       "      <td>22.8</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60249</td>\n",
       "      <td>Male</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>141.09</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension ever_married work_type Residence_type  \\\n",
       "0  28315    Male  38.0             0          Yes   Private          Rural   \n",
       "1  15104  Female  26.0             0          Yes   Private          Rural   \n",
       "2  26604  Female  18.0             0           No   Private          Rural   \n",
       "3  27916    Male  18.0             0           No   Private          Urban   \n",
       "4  60249    Male  13.0             0           No   Private          Urban   \n",
       "\n",
       "   avg_glucose_level   bmi smoking_status  stroke  \n",
       "0             108.68  32.7   never smoked       0  \n",
       "1              88.79  24.9   never smoked       0  \n",
       "2             107.82  26.0   never smoked       0  \n",
       "3              97.39  22.8   never smoked       0  \n",
       "4             141.09  24.0        Unknown       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем тестовые данные\n",
    "test = pd.read_csv(\"test_1.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc7942",
   "metadata": {},
   "source": [
    "##### Предварительная обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582a2bb1",
   "metadata": {},
   "source": [
    "**Проверяем типы данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf5f3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     int64\n",
       "gender                object\n",
       "age                  float64\n",
       "hypertension           int64\n",
       "heart_disease          int64\n",
       "ever_married          object\n",
       "work_type             object\n",
       "Residence_type        object\n",
       "avg_glucose_level    float64\n",
       "bmi                  float64\n",
       "smoking_status        object\n",
       "stroke                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c661587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender ['Male' 'Female' 'Other']\n",
      "ever_married ['Yes' 'No']\n",
      "Residence_type ['Urban' 'Rural']\n",
      "smoking_status ['formerly smoked' 'never smoked' 'smokes' 'Unknown']\n",
      "work_type ['Private' 'Self-employed' 'Govt_job' 'children' 'Never_worked']\n"
     ]
    }
   ],
   "source": [
    "features = ['gender', 'ever_married', 'Residence_type', 'smoking_status', 'work_type']\n",
    "for i in features:\n",
    "    print(i, train[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eabcb399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0   9046       1  67.0             0              1             1          2   \n",
       "1  51676       0  61.0             0              0             1          3   \n",
       "2  31112       1  80.0             0              1             1          2   \n",
       "3  60182       0  49.0             0              0             1          2   \n",
       "4   1665       0  79.0             1              0             1          3   \n",
       "\n",
       "   Residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n",
       "0               1             228.69  36.6               1       1  \n",
       "1               0             202.21   NaN               2       1  \n",
       "2               0             105.92  32.5               2       1  \n",
       "3               1             171.23  34.4               3       1  \n",
       "4               0             174.12  24.0               2       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "train_num = train.copy()\n",
    "test_num = test.copy()\n",
    "\n",
    "# категориальные -> числовые\n",
    "labelencoder = LabelEncoder()\n",
    "for i in features:\n",
    "    train_num[i] = labelencoder.fit_transform(train_num[i])\n",
    "    test_num[i] = labelencoder.fit_transform(test_num[i])\n",
    "    \n",
    "train_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e46b1fa",
   "metadata": {},
   "source": [
    "**Пропуски в данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8581801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "gender                 0\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "ever_married           0\n",
       "work_type              0\n",
       "Residence_type         0\n",
       "avg_glucose_level      0\n",
       "bmi                  157\n",
       "smoking_status         0\n",
       "stroke                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим, есть ли пропуски в данных\n",
    "train_num.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8fd5158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>28.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0   9046       1  67.0             0              1             1          2   \n",
       "1  51676       0  61.0             0              0             1          3   \n",
       "2  31112       1  80.0             0              1             1          2   \n",
       "3  60182       0  49.0             0              0             1          2   \n",
       "4   1665       0  79.0             1              0             1          3   \n",
       "\n",
       "   Residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n",
       "0               1             228.69  36.6               1       1  \n",
       "1               0             202.21  28.2               2       1  \n",
       "2               0             105.92  32.5               2       1  \n",
       "3               1             171.23  34.4               3       1  \n",
       "4               0             174.12  24.0               2       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Заполним пустые значения индекса массы тела медианными значениями в обучающей выборке\n",
    "median = train_num['bmi'].median()\n",
    "train_num['bmi'] = train_num['bmi'].fillna(median)\n",
    "train_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e12bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "gender                0\n",
       "age                   0\n",
       "hypertension          0\n",
       "ever_married          0\n",
       "work_type             0\n",
       "Residence_type        0\n",
       "avg_glucose_level     0\n",
       "bmi                  44\n",
       "smoking_status        0\n",
       "stroke                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd22118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28315</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>108.68</td>\n",
       "      <td>32.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15104</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>88.79</td>\n",
       "      <td>24.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26604</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>107.82</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27916</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>97.39</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60249</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>141.09</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  ever_married  work_type  Residence_type  \\\n",
       "0  28315       1  38.0             0             1          2               0   \n",
       "1  15104       0  26.0             0             1          2               0   \n",
       "2  26604       0  18.0             0             0          2               0   \n",
       "3  27916       1  18.0             0             0          2               1   \n",
       "4  60249       1  13.0             0             0          2               1   \n",
       "\n",
       "   avg_glucose_level   bmi  smoking_status  stroke  \n",
       "0             108.68  32.7               2       0  \n",
       "1              88.79  24.9               2       0  \n",
       "2             107.82  26.0               2       0  \n",
       "3              97.39  22.8               2       0  \n",
       "4             141.09  24.0               0       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Заполним пустые значения индекса массы тела медианными значениями в тестовой выборке\n",
    "median = test_num['bmi'].median()\n",
    "test_num['bmi'] = test_num['bmi'].fillna(median)\n",
    "test_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36125979",
   "metadata": {},
   "source": [
    "**Соотношение классов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb81ee9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3200\n",
       "1     210\n",
       "Name: heart_disease, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Целевая переменная\n",
    "train['heart_disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2f0948b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До балансировки\n",
      "(3410, 11)\n",
      "0    3200\n",
      "1     210\n",
      "Name: heart_disease, dtype: int64\n",
      "____________________________________________________________________________________________________\n",
      "После балансировки\n",
      "(6400, 11)\n",
      "heart_disease\n",
      "0                3200\n",
      "1                3200\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Создадим модель SMOTE, указав кол-во соседей 10\n",
    "os = SMOTE(random_state=0, k_neighbors=10)\n",
    "\n",
    "# вектор признаков\n",
    "X_train_not_os = train_num.drop(['heart_disease'], axis=1) \n",
    "# вектор целевой переменной\n",
    "y_train_not_os = train_num['heart_disease']\n",
    "\n",
    "column = X_train_not_os.columns\n",
    "\n",
    "print(\"До балансировки\")\n",
    "print(X_train_not_os.shape)\n",
    "print(y_train_not_os.value_counts())\n",
    "\n",
    "# Применим алгоритм балансировки\n",
    "X_train_os, y_train_os = os.fit_resample(X_train_not_os, y_train_not_os)\n",
    "X_train_os = pd.DataFrame(data=X_train_os, columns=column)\n",
    "y_train_os = pd.DataFrame(data=y_train_os, columns=['heart_disease'])\n",
    "\n",
    "print('_'*100)\n",
    "print(\"После балансировки\")\n",
    "print(X_train_os.shape)\n",
    "print(y_train_os.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86eae8f",
   "metadata": {},
   "source": [
    "##### Строим модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a708517",
   "metadata": {},
   "source": [
    "**Создаём нашу модель**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f9f1e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_os, y_train_os, test_size=0.3, random_state=1)\n",
    "\n",
    "DTC = DecisionTreeClassifier(random_state=11, max_features=\"auto\", max_depth=12)\n",
    "ABC = AdaBoostClassifier(base_estimator=DTC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de014ec",
   "metadata": {},
   "source": [
    "**Учим модель**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f2b82a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Артём\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.928125\n"
     ]
    }
   ],
   "source": [
    "ABC.fit(X_train, y_train)\n",
    "ABC_predict = ABC.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, ABC_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c72fa7",
   "metadata": {},
   "source": [
    "**Создаём финальную модель**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9d13261",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Артём\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=12,\n",
       "                                                         max_features='auto',\n",
       "                                                         random_state=11))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABC_f = AdaBoostClassifier(base_estimator=DTC)\n",
    "ABC_f.fit(X_train_os, y_train_os)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44877ebe",
   "metadata": {},
   "source": [
    "**Предсказываем значения**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70cf4e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = ABC_f.predict(test_num)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ee35e3",
   "metadata": {},
   "source": [
    "**Сверяем предсказанные значения с ответом**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31e45f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heart_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   heart_disease\n",
       "0              0\n",
       "1              0\n",
       "2              0\n",
       "3              0\n",
       "4              0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = pd.read_csv(\"answers_1.csv\")\n",
    "answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f06e8669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(answers, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b933a8d2",
   "metadata": {},
   "source": [
    "### Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc04f508",
   "metadata": {},
   "source": [
    "#### История создания и краткое описание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d143027f",
   "metadata": {},
   "source": [
    "В 1999 году от профессуры Стэнфордской кафедры статистики, а именно от Jerome Friedman, появилось обобщение наработок алгоритмов бустинга — **градиентный бустинг**, он же Gradient Boosting (Machine), он же GBM. Эта работа Friedman даёт статистическую базу для создания многих алгоритмов, предоставив общий подход бустинга как оптимизации в функциональном пространстве."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07acf75a",
   "metadata": {},
   "source": [
    "Градиентный бустинг ***последовательно добавляет к прошлым моделям новые таким образом, чтобы исправлялись ошибки, допущенные предыдущими предикторами.***\n",
    "Отличие градиентного бустинга от адаптивного заключается в том, что он пытается обучать новые модели по остаточной ошибке прошлых (двигаясь таким образом к минимуму функции потерь), в отличие от алгоритма AdaBoost, изменяющего веса классификаторов и признаков при каждой итерации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6371673f",
   "metadata": {},
   "source": [
    "Метод работы этого алгоритма основан на градиентном спуске, принцип которого достаточно просто и наглядно показан на картинке ниже. Наша цель - подобрать такие коэффициенты, параметры обучения и т.п., чтобы функция потерь - показатель сравнения между истинным ответом и предсказанием модели - стала минимальной, т.е. предсказание максимально приблизилось к истинному значению."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90332c99",
   "metadata": {},
   "source": [
    "![title](boosting_11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3957e9d",
   "metadata": {},
   "source": [
    "#### Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8cb7e5",
   "metadata": {},
   "source": [
    "Рассмотрим задачу распознавания объектов из многомерного пространства $\\mathfrak{X}$ с пространством меток $Y$. Пусть нам дана обучающая выборка $\\left\\{x_i\\right\\}^N_{i=1}$, где $N$ - число имеющихся признаков (размерность признакового пространства), $x_i \\in \\mathfrak{X}$. И пусть на ней известны истинные значения меток каждого объекта $\\left\\{y_i\\right\\}^N_{i=1}$, где\n",
    "$x_i \\in Y$. Необходимо построить распознающий оператор, который как можно более точно сможет предсказывать метки для каждого нового объекта $x_i \\in \\mathfrak{X}$.\n",
    "<br>Пусть нам задано некоторое семейство базовых алгоритмов $H$, каждый элемент $h\\left(x, a\\right) \\in H : \\mathfrak{X} → R$ которого определяется некоторым вектором параметров $a \\in A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98adbef",
   "metadata": {},
   "source": [
    "#### Построение алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdc5b3e",
   "metadata": {},
   "source": [
    "Будем искать финальный алгоритм классификации в виде линейной комбинации (композиции) имеющихся алгоритмов:\n",
    "$$F_M\\left(x\\right) = \\sum\\limits_{m=1}^M b_m h\\left(x, a_m\\right), b_m \\in \\mathbb{R}, a_m ∈ A.$$\n",
    "Однако подбор оптиматильного набора параметров $\\left\\{a_m, b_m\\right\\}^M_{m=1}$ – очень трудоемкая\n",
    "задача. Поэтому мы будем пытаться построить такую композицию путем жадного наращивания, каждый раз добавляя в сумму слагаемое, являющееся наиболее оптимальным алгоритмом из возможных. Будем считать, что нами уже построен классификатор $F_{m−1}$ длины $m−1$. Таким образом задача сводится к поиску пары наиболее оптимальных параметров $\\left\\{a_m, b_m\\right\\}$ для классификатора длины $m$:\n",
    "\n",
    "$$F_m\\left(x\\right) = F_{m−1}\\left(x\\right) + b_mh\\left(x, a_m\\right), b_m \\in \\mathbb{R}, a_m \\in A.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71300b3a",
   "metadata": {},
   "source": [
    "Что же подразумевает \"поиск наиболее оптимальных параметров\"? Это означает, что вводится некоторая функция потерь\n",
    "$L\\left(y_i, F_m\\left(x_i\\right)\\right), i = 1, ..., N,$ показывающая, как \"сильно\" предсказанный ответ\n",
    "$F_m\\left(x_i\\right)$ отличается от правильного ответа $y_i$. И затем минимизируется функционал\n",
    "ошибки\n",
    "\n",
    "$$Q =\\sum\\limits_{i=1}^N L\\left(y_i, F_m\\left(x_i\\right)\\right) \\rightarrow \\min.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6302a028",
   "metadata": {},
   "source": [
    "Заметим, что функционал ошибки $Q$ – вещественная функция, зависящая от точек $\\left\\{F_m\\left(x_i\\right)\\right\\}^N_{i=1}$ в $N$-мерном пространстве, и нам необходимо решить задачу минимизации этого функционала. Сделаем это, реализуя один шаг метода градиентного спуска. В качестве точки, для которой мы будем искать оптимальное приращение, рассмотрим $F_{m−1}$. Найдем градиент функционала ошибки:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f5893b",
   "metadata": {},
   "source": [
    "$$\\nabla Q= \\left[\\frac{\\partial Q}{\\partial F_{m-1}}\\left(x_i\\right)\\right]^N_{i=1} = \\left[\\frac{\\partial \\left(\\sum\\limits_{i=1}^N L\\left(y_i, F_{m-1}\\right)\\right)}{\\partial F_{m-1}}\\left(x_i\\right)\\right]^N_{i=1} = \\left[\\frac{\\partial L\\left(y_i, F_{m-1}\\right)}{\\partial F_{m-1}}\\left(x_i\\right)\\right]^N_{i=1}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94834907",
   "metadata": {},
   "source": [
    "Таким образом, в силу метода градиентного спуска, наиболее выгодно добавить новое слагаемое в классификатор следующим образом: \n",
    "\n",
    "$$F_m = F_{m−1} − b_m\\nabla Q, b_m \\in \\mathbb{R},$$\n",
    "\n",
    "где $b_m$ подбирается линейным поиском по вещественным числам $\\mathbb{R}$:\n",
    "\n",
    "$$b_m = \\argmin_{b \\in \\mathbb{R}} \\sum\\limits_{i=1}^N L\\left(y_i, F_{m-1}\\left(x_i\\right) - b \\nabla Q_i\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fafa864",
   "metadata": {},
   "source": [
    "Однако $\\nabla Q$ представляет из себя лишь вектор оптимальных значений для каждого объекта $x_i$, а не базовый алгоритм из семейства $H$, определенный $\\forall{x} \\in \\mathfrak{X}$. Поэтому нам необходимо найти $h\\left(x, a_m\\right) \\in H$, наиболее похожий на $\\nabla Q$. Сделаем это, опять минимизируя функционал ошибки:\n",
    "\n",
    "$$a_m = \\argmin_{a \\in A} \\sum\\limits_{i=1}^N L\\left( \\nabla Q_i,h\\left(x_i,a\\right)\\right) \\equiv обучить \\left(\\left\\{x_i\\right\\}^N_{i=1}, \\left\\{\\nabla Q_i\\right\\}^N_{i=1}\\right),$$\n",
    "\n",
    "что просто соотвествует базовому алгоритму обучения. Далее найдем коэффициент $b_m$, используя линейный поиск:\n",
    "\n",
    "$$b_m = \\argmin_{b \\in \\mathbb{R}} \\sum\\limits_{i=1}^N L\\left(y_i, F_{m-1}\\left(x_i\\right) - bh\\left(x_i,a_m\\right)\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d322669",
   "metadata": {},
   "source": [
    "Итоговый алгоритм имеет следующий вид:\n",
    "1. Инициализация начального классификатора $F_0\\left(x\\right) = learn\\left(\\left\\{x_i\\right\\}^N_{i=1}, \\left\\{y_i\\right\\}^N_{i=1}\\right)$.\n",
    "2. Пока $m\\leq M$, выполняем следующий цикл:\n",
    "<br>    ◉ Находим градиент функционала ошибки: $\\nabla Q = \\left[\\frac{\\partial L\\left(y_i, F_{m-1}\\right)}{\\partial F_{m-1}}\\left(x_i\\right)\\right]^N_{i=1}$.\n",
    "<br>    ◉ Находим вектор параметров алгоритма классификации из семейства базовых алгоритмов $H$: $a_m = \\argmin_{a \\in A} \\sum\\limits_{i=1}^N L\\left( \\nabla Q_i,h\\left(x_i,a\\right)\\right) \\equiv обучить \\left(\\left\\{x_i\\right\\}^N_{i=1}, \\left\\{\\nabla Q_i\\right\\}^N_{i=1}\\right)$.\n",
    "<br>    ◉ Ищем коэффициенты линейной комбинации классификаторов из базового семейства $H$: $b_m = \\argmin_{b \\in \\mathbb{R}} \\sum\\limits_{i=1}^N L\\left(y_i, F_{m-1}\\left(x_i\\right) - bh\\left(x_i,a_m\\right)\\right)$.\n",
    "<br>    ◉ Вычисляем очередной (промежуточный) алгоритм классификации: $F_m\\left(x\\right) = F_{m−1}\\left(x\\right) + b_mh\\left(x, a_m\\right)$.\n",
    "<br>    ◉ Увеличим счетчик итераций: $m = m + 1$.\n",
    "3. Заканчиваем цикл и получаем результирующий алгоритм: $F_M\\left(x\\right) = \\sum\\limits_{m=1}^M b_m h\\left(x, a_m\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689413a1",
   "metadata": {},
   "source": [
    "![title](boosting_12.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9499ac9",
   "metadata": {},
   "source": [
    "#### Частные случаи градиентного бустинга"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82902d65",
   "metadata": {},
   "source": [
    "##### Решение задачи регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388db67a",
   "metadata": {},
   "source": [
    "Рассмотрим частные случаи для решения задач регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec0404d",
   "metadata": {},
   "source": [
    "**1. Метод наименьших квадратов.** Рассмотрим следующую функцию потерь (L2 Loss Function, или Gaussian Loss Function):\n",
    "\n",
    "$$L\\left(y, F\\right) = \\frac {\\left(y − F\\right)^2} {2}.$$\n",
    "\n",
    "Тогда $-\\nabla Q$ в алгоритме градиентного бустинга примет следующий вид:\n",
    "\n",
    "$$-\\nabla Q = y_i − F_{m−1}\\left(x_i\\right).$$\n",
    "\n",
    "Этот случай бустинга называется LS-boosting (Least-Squares Boosting) или GentleBoost. Это классическое условное среднее, самый частый и простой вариант. Если нет никакой дополнительной информации или требований к устойчивости модели — рекомендуется использовать его."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3e65c",
   "metadata": {},
   "source": [
    "**2. Минимизация среднего модуля отклонения.** Далее рассмотрим еще более простой вариант функции потерь – модуль отклонения: (L1 Loss Function, или Laplacian Loss Function):\n",
    "\n",
    "$$L\\left(y, F\\right) = \\left| y - F \\right|.$$\n",
    "\n",
    "Тогда $-\\nabla Q$ примет следующий вид:\n",
    "\n",
    "$$-\\nabla Q = \\text{sign} \\left(y_i − F_{m−1}\\left(x_i\\right)\\right).$$\n",
    "\n",
    "А линейный поиск приобретает следующий вид:\n",
    "\n",
    "$$b_m = \\argmin_{b \\in \\mathbb(R)} \\sum\\limits_{i=1}^N \\left| y_i−F_{m−1}\\left(x_i\\right)−bh\\left(x_i, a_m\\right)\\right| = \\argmin_{b \\in \\mathbb(R)} \\sum\\limits_{i=1}^N \\left|h\\left(x_i, a_m\\right)\\right|\\left| \\frac {y_i−F_{m−1}\\left(x_i\\right)} {h\\left(x_i, a_m\\right)}−b\\right| = \\text{median}_W \\left\\{\\frac {y_i−F_{m−1}\\left(x_i\\right)} {h\\left(x_i, a_m\\right)}−b \\right\\}^N_{i=1},$$\n",
    "\n",
    "$$W=\\left\\{ h\\left(x_i, a_m\\right)\\right\\}^N_{i=1}, $$\n",
    "\n",
    "где $\\text{median}_W$ – взвешенное медианное значение набора. То есть задача свелась к задаче поиска порядковой статистики в массиве, а для нее существуют решения за O(N), что заметно быстрее линейного поиска по вещественным числам. Такая разновидность бустинга называется LAD-boosting (Least-Absolute-Deviation Boosting). На первый взгляд, это не очень дифференцируемая вещь, на самом деле определяет условную медиану. Медиана более устойчива к выбросам, поэтому в некоторых задачах эта функция потерь предпочтительнее, так как она не так сильно штрафует большие отклонения, нежели квадратичная функция."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f92111",
   "metadata": {},
   "source": [
    "**3. Функция потерь пинбольного шарика.** Выбираем в качестве функции потерь функцию, состоящую из двух участков прямых с разными наклонами ($L_q$ Loss Function, или Quantile Loss Function):\n",
    "\n",
    "$$L\\left(y, F\\right) = \n",
    " \\begin{cases}\n",
    "   \\left(1-\\alpha \\right)\\left(F-y \\right), &y \\leqslant F,\\\\\n",
    "   \\alpha\\left(y-F \\right), &y > F,\n",
    " \\end{cases}$$\n",
    " \n",
    "где $\\alpha \\in \\left(0, 1\\right)$. Если бы мы, допустим, захотели не условную медиану с $L_1$, а условную 75%-квантиль, мы бы могли воспользоваться этим вариантом с $\\alpha = 0.75$. Данная функция является ассиметричной и больше штрафует наблюдения, оказывающиеся по нужную нам сторону квантили."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318f3249",
   "metadata": {},
   "source": [
    "**4. M-бустинг.** В некоторых задачах выгоднее использовать не квадратичную функцию потерь, а ее модификацию, функцию потерь Хубера. Она имеет вид квадратичной функции потерь вблизи нуля и линейной функции потерь вдали от нуля:\n",
    "\n",
    "$$L\\left(y, F\\right) = \n",
    "\\begin{cases}\n",
    "   \\frac {1} {2}\\left(y-F \\right)^2, &\\left|y-F\\right| \\leqslant \\sigma,\\\\\n",
    "   \\sigma\\left(\\left|y-F\\right| - \\frac {\\sigma} {2}\\right), &\\left|y-F\\right| > \\sigma.\\\n",
    " \\end{cases}$$\n",
    " \n",
    "Это позволяет использовать метод наименьших квадратов для небольших ошибок и линейную функцию потерь для больших ошибок, что существенно изменяет алгоритм для распределений ошибки с тяжелыми хвостами и очень полезно для многих задач (например, для задач с сильно зашумленными данными). Бустинг с использованием функции потерь Хубера называется M-бустингом."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e102c23a",
   "metadata": {},
   "source": [
    "![title](boosting_13.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d5f45a",
   "metadata": {},
   "source": [
    "##### Решение задачи классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a56c69",
   "metadata": {},
   "source": [
    "Идея бустинга, как мы видели ранее, также применима для задачи классификации. В случае бинарной классификации это означает, что $Y = \\left\\{−1, +1\\right\\}$. Тогда часто подразумевается, что каждый алгоритм $h \\in H$ возващает «степень» принадлежности объекта к некоторому классу, а результирующий классификатор $F$ получается применением порогового правила к композиции (линейной комбинации)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e0a478",
   "metadata": {},
   "source": [
    "В случае классификации обычно используется функция потерь от одного аргумента: $L\\left(y, F\\right) = L\\left(yF\\right)$, т.е. отступ (расстояние) заменяется произведением настоящего класса и предсказанного значения. В таком случае под градиентом функционала ошибки можно подразумевать вектор весов обучающих объектов, поэлементно умноженный на верные значения классов:\n",
    "\n",
    "$$\\nabla Q = \\left[\\frac{\\partial L\\left(y_i F_{m-1}\\right)}{\\partial F_{m-1}}\\left(x_i\\right)\\right]^N_{i=1} = \n",
    "\\left[y_i\\frac{\\partial L\\left(y_i F_{m-1}\\right)}{\\partial y_i F_{m-1}}\\left(x_i\\right)\\right]^N_{i=1} = \n",
    "\\left[y_i w_i\\right]^N_{i=1},$$\n",
    "\n",
    "где $w_i \\equiv \\frac{\\partial L\\left(y_i F_{m-1}\\right)}{\\partial y_i F_{m-1}}\\left(x_i\\right)$. Тогда алгоритм обучения $h\\left(x, a_m\\right)$ определяется параметрами $a_m$, которые приобретают следующий вид:\n",
    "\n",
    "$$a_m = обучить \\left(\\left\\{x_i\\right\\}^N_{i=1}, \\left\\{\\nabla Q_i\\right\\}^N_{i=1}\\right) = \\argmin_{a \\in A} \\sum\\limits_{i=1}^N L\\left( \\nabla Q_i h\\left(x_i,a\\right)\\right) = \\argmin_{a \\in A} \\sum\\limits_{i=1}^N L\\left( y_i w_i h\\left(x_i,a\\right)\\right)$$\n",
    "\n",
    "Таким образом, $w_i$ можно рассматривать с точки зрения весов (степени «важности»), которые придаются объектам и учитываются при обучении каждого базового алгоритма. Этот взгляд сложился исторически раньше, чем градиентный подход. К тому же, он более интуитивно понятен."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec596ef2",
   "metadata": {},
   "source": [
    "**1. AdaBooost.** Рассмотренный ранее алгоритм является частным случаем градиентного бустинга и подразумевает, что используется экспоненциальная функция потерь:\n",
    "\n",
    "$$L\\left(y, F\\right) = \\exp\\left(−yF\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb45be",
   "metadata": {},
   "source": [
    "**2. Real AdaBoost.**  Расмотренная нами ранняя версия AdaBoost (который по факту является Дискретным AdaBoost (Discrete AdaBoost)) рассматривала композицию из алгоритмов $h \\in H$, которые лишь *возвращают значения* из $\\left\\{−1, +1\\right\\}$. Затем он был обобщен на случай, когда алгоритмы $h \\in H$ *возвращают вероятность принадлежности классу* $\\left\\{+1\\right\\}$. Последний как раз и является Вещественным AdaBoost (Real AdaBoost)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67306c9d",
   "metadata": {},
   "source": [
    "**3. LogitBoost.** Попробуем строить композицию бинарных классификаторов, используя идеи логистической регрессии. Функция потерь имеет вид:\n",
    "\n",
    "$$L\\left(y, F\\right) = \\log(1 + \\exp \\left(−2yF\\right)),$$\n",
    "\n",
    "где\n",
    "\n",
    "$$F\\left(x\\right) = \\frac {1} {2} \\log \\frac {P\\left(y = 1|x\\right)} {P\\left(y = -1|x\\right)}$$\n",
    "\n",
    "Такая разновидность бустинга называется LogitBoost. Как мы видим, основное отличие LogitBoost от AdaBoost состоит в том, что AdaBoost использует экспоненциальную функцию потерь, а LogitBoost – логистическую. За счет этого в некоторых случаях LogitBoost может превосходить по точности AdaBoost, а также быть более устойчивым к шумам в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779280bc",
   "metadata": {},
   "source": [
    "**4. Мультиклассовая классификация.** Идея бустинга для бинарной классификации легко обобщается на случай K классов. Вводится следующая функция потерь:\n",
    "\n",
    "$$L\\left(y, F\\right) = - \\sum\\limits_{i=1}^K y_i \\log p_i \\left(x\\right).$$\n",
    "\n",
    "Здесь $y_i \\in \\left\\{0, 1\\right\\}$ показывает принадлежность объекта к классу $i$, а $p_i$ показывает вероятность принадлежности объекта классу $i$, получаемая в ходе работы логистической регрессии. Формулы для классификатора класса K мультиклассовой логистической регрессии имеют вид:\n",
    "\n",
    "$$f_k\\left(x\\right) = \\log p_k\\left(x\\right) − \\frac {1} {K} \\sum\\limits_{l=1}^K \\log p_l\\left(x\\right).$$\n",
    "\n",
    "После преобразований можно получить:\n",
    "\n",
    "$$\\nabla Q_i = y_{ik} − p_{k,m−1}\\left(x_i\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f15b64",
   "metadata": {},
   "source": [
    "#### Гиперпараметры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677300db",
   "metadata": {},
   "source": [
    "**min_samples_split**: минимальное число точек, необходимое для разделения. Полезно, чтобы избегать переобучения.\n",
    "<br>**min_samples_leaf**: минимальное количество элементов в листе или узле дерева. Меньшие значения следует выбирать для несбалансированных выборок.\n",
    "<br>**min_weight_fraction_leaf**: похож на предыдущий, только вместо количества задает долю от общего числа элементов.\n",
    "<br>**max_depth**: максимальная глубина дерева. Используется для борьбы с переобучением.\n",
    "<br>**max_lead_nodes**: максимальное число конечных листьев у дерева. Если задан этот гиперпараметр, то предыдущий игнорируется.\n",
    "<br>**max_features**: количество признаков, учитываемых алгоритмом при поиске лучшего разделения.\n",
    "<br>**loss** *{‘squared_error’, ‘absolute_error’, ‘huber’, ‘quantile’}*: функция потерь, по умолчанию squared_error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e59fe3",
   "metadata": {},
   "source": [
    "#### Достоинства"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbbd55c",
   "metadata": {},
   "source": [
    "**⌘** Возможность рассматривать различные функции потерь. Это позволяет решать как задачи классификации, так и задачи регрессии. К тому же, возможность выбора произвольной функции потерь позволяет акцентировать внимание на особенностях данных в задаче.\n",
    "<br>**⌘** Возможность рассмотрения любого семейства базовых алгоритмов, что дает широкиие возможности учета особенностей даннной задачи. Бустинг над решающими деревьями считается одним из наиболее эффективных вариантов бустинга. А учитывая, что решающие деревья в свою очередь тоже используют базовые алгоритмы (например, пороговые, линейные и т.п.), в результате получается огромное количество вариантов для настройки.\n",
    "<br>**⌘** Благодаря достаточной простоте метода и четкому математическому обоснованию, в каждой конкретной вариации бустинга не сложно провести некоторые математические и алгоритмические оптимизации, которые заметно ускорят работу алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fe84f1",
   "metadata": {},
   "source": [
    "#### Недостатки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cdea96",
   "metadata": {},
   "source": [
    "**⌘** Градиентный бустинг – трудоемкий метод, и работает он достаточно медленно. Зачастую требуется построение сотен или даже тысяч базовых алгоритмов для композиции.\n",
    "<br>**⌘** Без дополнительных модификаций он имеет свойство полностью подстраиваться под данные, в том числе под ошибки и выбросы в них.\n",
    "<br>**⌘** Идея бустинга обычно плохо применима к построению композиции из достаточно сложных и мощных алгоритмов. Построение такой композиции занимает очень много времени, а качество существенно не увеличивается.\n",
    "<br>**⌘** Результаты работы градиентного бустинга сложно интерпретируемы, особенно если в композицию входят десятки алгоритмов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b6af9",
   "metadata": {},
   "source": [
    "#### Пример использования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2106c",
   "metadata": {},
   "source": [
    "##### Считываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cb61ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>school_setting</th>\n",
       "      <th>school_type</th>\n",
       "      <th>classroom</th>\n",
       "      <th>teaching_method</th>\n",
       "      <th>n_student</th>\n",
       "      <th>student_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>lunch</th>\n",
       "      <th>pretest</th>\n",
       "      <th>posttest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VKWQH</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Public</td>\n",
       "      <td>IEM</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NNWQ5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>51.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOOBU</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Public</td>\n",
       "      <td>U6J</td>\n",
       "      <td>Standard</td>\n",
       "      <td>25.0</td>\n",
       "      <td>OKZQZ</td>\n",
       "      <td>Female</td>\n",
       "      <td>Qualifies for reduced/free lunch</td>\n",
       "      <td>31.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCAAW</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Non-public</td>\n",
       "      <td>2B1</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>18.0</td>\n",
       "      <td>X4NP9</td>\n",
       "      <td>Female</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>67.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GJJHK</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Public</td>\n",
       "      <td>YUC</td>\n",
       "      <td>Standard</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3RFLZ</td>\n",
       "      <td>Female</td>\n",
       "      <td>Qualifies for reduced/free lunch</td>\n",
       "      <td>45.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KZKKE</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Public</td>\n",
       "      <td>3D0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>22.0</td>\n",
       "      <td>BT8BY</td>\n",
       "      <td>Male</td>\n",
       "      <td>Qualifies for reduced/free lunch</td>\n",
       "      <td>28.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school school_setting school_type classroom teaching_method  n_student  \\\n",
       "0  VKWQH          Rural      Public       IEM    Experimental       22.0   \n",
       "1  GOOBU          Urban      Public       U6J        Standard       25.0   \n",
       "2  CCAAW       Suburban  Non-public       2B1    Experimental       18.0   \n",
       "3  GJJHK       Suburban      Public       YUC        Standard       21.0   \n",
       "4  KZKKE          Rural      Public       3D0        Standard       22.0   \n",
       "\n",
       "  student_id  gender                             lunch  pretest  posttest  \n",
       "0      NNWQ5    Male                  Does not qualify     51.0      61.0  \n",
       "1      OKZQZ  Female  Qualifies for reduced/free lunch     31.0      44.0  \n",
       "2      X4NP9  Female                  Does not qualify     67.0      81.0  \n",
       "3      3RFLZ  Female  Qualifies for reduced/free lunch     45.0      49.0  \n",
       "4      BT8BY    Male  Qualifies for reduced/free lunch     28.0      42.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем тренировочные данные\n",
    "train = pd.read_csv(\"train_2.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd4b803a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>school_setting</th>\n",
       "      <th>school_type</th>\n",
       "      <th>classroom</th>\n",
       "      <th>teaching_method</th>\n",
       "      <th>n_student</th>\n",
       "      <th>student_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>lunch</th>\n",
       "      <th>pretest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOBU</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Public</td>\n",
       "      <td>PBA</td>\n",
       "      <td>Standard</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4TYTZ</td>\n",
       "      <td>Male</td>\n",
       "      <td>Qualifies for reduced/free lunch</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUQAM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Public</td>\n",
       "      <td>OMI</td>\n",
       "      <td>Standard</td>\n",
       "      <td>28.0</td>\n",
       "      <td>AYOIP</td>\n",
       "      <td>Female</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOBU</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Public</td>\n",
       "      <td>18K</td>\n",
       "      <td>Standard</td>\n",
       "      <td>31.0</td>\n",
       "      <td>P6MIL</td>\n",
       "      <td>Female</td>\n",
       "      <td>Qualifies for reduced/free lunch</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CIMBB</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Non-public</td>\n",
       "      <td>HUJ</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>17.0</td>\n",
       "      <td>V69IG</td>\n",
       "      <td>Female</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUQAM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Public</td>\n",
       "      <td>1Q1</td>\n",
       "      <td>Standard</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6AEX4</td>\n",
       "      <td>Female</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school school_setting school_type classroom teaching_method  n_student  \\\n",
       "0  GOOBU          Urban      Public       PBA        Standard       24.0   \n",
       "1  CUQAM          Urban      Public       OMI        Standard       28.0   \n",
       "2  GOOBU          Urban      Public       18K        Standard       31.0   \n",
       "3  CIMBB          Urban  Non-public       HUJ    Experimental       17.0   \n",
       "4  CUQAM          Urban      Public       1Q1        Standard       28.0   \n",
       "\n",
       "  student_id  gender                             lunch  pretest  \n",
       "0      4TYTZ    Male  Qualifies for reduced/free lunch     37.0  \n",
       "1      AYOIP  Female                  Does not qualify     51.0  \n",
       "2      P6MIL  Female  Qualifies for reduced/free lunch     48.0  \n",
       "3      V69IG  Female                  Does not qualify     64.0  \n",
       "4      6AEX4  Female                  Does not qualify     52.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем тестовые данные\n",
    "test = pd.read_csv(\"test_2.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2250e759",
   "metadata": {},
   "source": [
    "##### Предварительная обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3f2d56",
   "metadata": {},
   "source": [
    "**Проверяем типы данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "511e079e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school              object\n",
       "school_setting      object\n",
       "school_type         object\n",
       "classroom           object\n",
       "teaching_method     object\n",
       "n_student          float64\n",
       "student_id          object\n",
       "gender              object\n",
       "lunch               object\n",
       "pretest            float64\n",
       "posttest           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faa341c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school ['VKWQH' 'GOOBU' 'CCAAW' 'GJJHK' 'KZKKE' 'UAGPU' 'KFZMY' 'IDGFP' 'CUQAM'\n",
      " 'ANKYI' 'QOQTS' 'UKPGS' 'ZOWMK' 'VVTVA' 'LAYPA' 'OJOBU' 'UUUQX' 'ZMNYA'\n",
      " 'FBUMG' 'CIMBB' 'DNQDD' 'GOKXL' 'VHDHF']\n",
      "school_setting ['Rural' 'Urban' 'Suburban']\n",
      "school_type ['Public' 'Non-public']\n",
      "classroom ['IEM' 'U6J' '2B1' 'YUC' '3D0' '62L' '21Q' '98D' '341' 'D33' 'BFY' 'ZNS'\n",
      " 'X2O' 'IPU' '05H' 'QA2' 'YTB' 'O6A' 'S98' 'PGH' '08N' 'KXB' '9AW' '3XJ'\n",
      " 'NOR' 'AJ1' 'HKF' 'XJ8' '6C1' 'W8A' '1UU' '5SZ' 'TB5' 'IQN' 'JGD' 'HCB'\n",
      " 'P2A' 'HUJ' '1VD' 'NWZ' '2AP' 'CXC' 'UWK' 'J8J' 'ZDT' 'V77' 'A93' 'ZBH'\n",
      " 'A33' 'G2L' 'XXJ' 'GYM' 'ROP' '5LQ' 'CII' '1Q1' '197' 'XZM' 'SUR' 'PC6'\n",
      " 'P8I' 'X6Z' 'XXE' 'ENO' 'ST7' '4NN' '18K' 'EID' 'TSA' 'J6X' 'DFQ' 'XZ4'\n",
      " 'OMI' 'FS3' 'PGK' 'RK7' 'UHU' 'Q0E' 'AE1' 'PBA' 'PW5' '6U9' 'QTU' 'CD8'\n",
      " '0N7' '6OL' '7BL' 'RA5' 'X78' '1SZ' 'KR1' 'VA6' 'SSP' '5JK' 'H7S' 'EPS'\n",
      " '2BR']\n",
      "teaching_method ['Experimental' 'Standard']\n",
      "student_id ['NNWQ5' 'OKZQZ' 'X4NP9' ... 'W6HC7' 'E794Z' 'D76QH']\n",
      "gender ['Male' 'Female']\n",
      "lunch ['Does not qualify' 'Qualifies for reduced/free lunch']\n"
     ]
    }
   ],
   "source": [
    "features = ['school', 'school_setting', 'school_type', 'classroom', 'teaching_method', 'student_id', \n",
    "            'gender', 'lunch']\n",
    "for i in features:\n",
    "    print(i, train[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2e0d5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>school_setting</th>\n",
       "      <th>school_type</th>\n",
       "      <th>classroom</th>\n",
       "      <th>teaching_method</th>\n",
       "      <th>n_student</th>\n",
       "      <th>gender</th>\n",
       "      <th>lunch</th>\n",
       "      <th>pretest</th>\n",
       "      <th>posttest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VKWQH</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Public</td>\n",
       "      <td>IEM</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>51.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOOBU</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Public</td>\n",
       "      <td>U6J</td>\n",
       "      <td>Standard</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Qualifies for reduced/free lunch</td>\n",
       "      <td>31.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCAAW</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Non-public</td>\n",
       "      <td>2B1</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>67.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GJJHK</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Public</td>\n",
       "      <td>YUC</td>\n",
       "      <td>Standard</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Qualifies for reduced/free lunch</td>\n",
       "      <td>45.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KZKKE</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Public</td>\n",
       "      <td>3D0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Qualifies for reduced/free lunch</td>\n",
       "      <td>28.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>ANKYI</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Non-public</td>\n",
       "      <td>6OL</td>\n",
       "      <td>Standard</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>64.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>VKWQH</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Public</td>\n",
       "      <td>GYM</td>\n",
       "      <td>Standard</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>48.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>OJOBU</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Public</td>\n",
       "      <td>5SZ</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>62.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>LAYPA</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Public</td>\n",
       "      <td>J8J</td>\n",
       "      <td>Standard</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>65.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>GOOBU</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Public</td>\n",
       "      <td>W8A</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Qualifies for reduced/free lunch</td>\n",
       "      <td>40.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1798 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school school_setting school_type classroom teaching_method  n_student  \\\n",
       "0     VKWQH          Rural      Public       IEM    Experimental       22.0   \n",
       "1     GOOBU          Urban      Public       U6J        Standard       25.0   \n",
       "2     CCAAW       Suburban  Non-public       2B1    Experimental       18.0   \n",
       "3     GJJHK       Suburban      Public       YUC        Standard       21.0   \n",
       "4     KZKKE          Rural      Public       3D0        Standard       22.0   \n",
       "...     ...            ...         ...       ...             ...        ...   \n",
       "1793  ANKYI          Urban  Non-public       6OL        Standard       20.0   \n",
       "1794  VKWQH          Rural      Public       GYM        Standard       20.0   \n",
       "1795  OJOBU          Rural      Public       5SZ    Experimental       17.0   \n",
       "1796  LAYPA          Rural      Public       J8J        Standard       19.0   \n",
       "1797  GOOBU          Urban      Public       W8A    Experimental       26.0   \n",
       "\n",
       "      gender                             lunch  pretest  posttest  \n",
       "0       Male                  Does not qualify     51.0      61.0  \n",
       "1     Female  Qualifies for reduced/free lunch     31.0      44.0  \n",
       "2     Female                  Does not qualify     67.0      81.0  \n",
       "3     Female  Qualifies for reduced/free lunch     45.0      49.0  \n",
       "4       Male  Qualifies for reduced/free lunch     28.0      42.0  \n",
       "...      ...                               ...      ...       ...  \n",
       "1793    Male                  Does not qualify     64.0      76.0  \n",
       "1794    Male                  Does not qualify     48.0      61.0  \n",
       "1795    Male                  Does not qualify     62.0      77.0  \n",
       "1796    Male                  Does not qualify     65.0      72.0  \n",
       "1797    Male  Qualifies for reduced/free lunch     40.0      60.0  \n",
       "\n",
       "[1798 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(['student_id'], axis=1)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbd62129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>school_setting</th>\n",
       "      <th>school_type</th>\n",
       "      <th>classroom</th>\n",
       "      <th>teaching_method</th>\n",
       "      <th>n_student</th>\n",
       "      <th>gender</th>\n",
       "      <th>lunch</th>\n",
       "      <th>pretest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOBU</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Public</td>\n",
       "      <td>PBA</td>\n",
       "      <td>Standard</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Qualifies for reduced/free lunch</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUQAM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Public</td>\n",
       "      <td>OMI</td>\n",
       "      <td>Standard</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOBU</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Public</td>\n",
       "      <td>18K</td>\n",
       "      <td>Standard</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Qualifies for reduced/free lunch</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CIMBB</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Non-public</td>\n",
       "      <td>HUJ</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUQAM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Public</td>\n",
       "      <td>1Q1</td>\n",
       "      <td>Standard</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>CCAAW</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Non-public</td>\n",
       "      <td>IQN</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>UKPGS</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Public</td>\n",
       "      <td>KXB</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>CCAAW</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Non-public</td>\n",
       "      <td>2B1</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Qualifies for reduced/free lunch</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>VVTVA</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Public</td>\n",
       "      <td>TB5</td>\n",
       "      <td>Standard</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Qualifies for reduced/free lunch</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>GOKXL</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Public</td>\n",
       "      <td>ENO</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Does not qualify</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school school_setting school_type classroom teaching_method  n_student  \\\n",
       "0    GOOBU          Urban      Public       PBA        Standard       24.0   \n",
       "1    CUQAM          Urban      Public       OMI        Standard       28.0   \n",
       "2    GOOBU          Urban      Public       18K        Standard       31.0   \n",
       "3    CIMBB          Urban  Non-public       HUJ    Experimental       17.0   \n",
       "4    CUQAM          Urban      Public       1Q1        Standard       28.0   \n",
       "..     ...            ...         ...       ...             ...        ...   \n",
       "330  CCAAW       Suburban  Non-public       IQN    Experimental       15.0   \n",
       "331  UKPGS       Suburban      Public       KXB    Experimental       18.0   \n",
       "332  CCAAW       Suburban  Non-public       2B1    Experimental       18.0   \n",
       "333  VVTVA          Urban      Public       TB5        Standard       25.0   \n",
       "334  GOKXL          Rural      Public       ENO    Experimental       22.0   \n",
       "\n",
       "     gender                             lunch  pretest  \n",
       "0      Male  Qualifies for reduced/free lunch     37.0  \n",
       "1    Female                  Does not qualify     51.0  \n",
       "2    Female  Qualifies for reduced/free lunch     48.0  \n",
       "3    Female                  Does not qualify     64.0  \n",
       "4    Female                  Does not qualify     52.0  \n",
       "..      ...                               ...      ...  \n",
       "330    Male                  Does not qualify     63.0  \n",
       "331    Male                  Does not qualify     78.0  \n",
       "332    Male  Qualifies for reduced/free lunch     63.0  \n",
       "333    Male  Qualifies for reduced/free lunch     40.0  \n",
       "334  Female                  Does not qualify     60.0  \n",
       "\n",
       "[335 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.drop(['student_id'], axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "120d0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['school', 'school_setting', 'school_type', 'classroom', 'teaching_method', 'gender', 'lunch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8efbdc9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>school_setting</th>\n",
       "      <th>school_type</th>\n",
       "      <th>classroom</th>\n",
       "      <th>teaching_method</th>\n",
       "      <th>n_student</th>\n",
       "      <th>gender</th>\n",
       "      <th>lunch</th>\n",
       "      <th>pretest</th>\n",
       "      <th>posttest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school  school_setting  school_type  classroom  teaching_method  n_student  \\\n",
       "0      19               0            1         47                0       22.0   \n",
       "1       8               2            1         78                1       25.0   \n",
       "2       1               1            0         11                0       18.0   \n",
       "3       6               1            1         93                1       21.0   \n",
       "4      11               0            1         14                1       22.0   \n",
       "\n",
       "   gender  lunch  pretest  posttest  \n",
       "0       1      0     51.0      61.0  \n",
       "1       0      1     31.0      44.0  \n",
       "2       0      0     67.0      81.0  \n",
       "3       0      1     45.0      49.0  \n",
       "4       1      1     28.0      42.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num = train.copy()\n",
    "test_num = test.copy()\n",
    "\n",
    "# категориальные -> числовые\n",
    "labelencoder = LabelEncoder()\n",
    "for i in features:\n",
    "    train_num[i] = labelencoder.fit_transform(train_num[i])\n",
    "    test_num[i] = labelencoder.fit_transform(test_num[i])\n",
    "    \n",
    "train_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a0416a",
   "metadata": {},
   "source": [
    "**Пропуски в данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20173de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school             0\n",
       "school_setting     0\n",
       "school_type        0\n",
       "classroom          0\n",
       "teaching_method    0\n",
       "n_student          0\n",
       "gender             0\n",
       "lunch              0\n",
       "pretest            0\n",
       "posttest           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим, есть ли пропуски в данных\n",
    "train_num.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7ba3d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school             0\n",
       "school_setting     0\n",
       "school_type        0\n",
       "classroom          0\n",
       "teaching_method    0\n",
       "n_student          0\n",
       "gender             0\n",
       "lunch              0\n",
       "pretest            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73e5b51",
   "metadata": {},
   "source": [
    "**Создаем вектор целевой переменной**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cb6970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вектор признаков\n",
    "X_train_num = train_num.drop(['posttest'], axis=1) \n",
    "# вектор целевой переменной\n",
    "y_train_num = train_num['posttest']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b57f3",
   "metadata": {},
   "source": [
    "##### Строим модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28bcda6",
   "metadata": {},
   "source": [
    "**Создаём нашу модель**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6883371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score as r2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_num, y_train_num, test_size=0.3, random_state=1)\n",
    "\n",
    "GBR = GradientBoostingRegressor(loss='squared_error', max_depth=3, n_estimators=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea07d14",
   "metadata": {},
   "source": [
    "**Учим модель**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4260022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9440518874401554\n"
     ]
    }
   ],
   "source": [
    "GBR.fit(X_train, y_train)\n",
    "GBR_predict = GBR.predict(X_test)\n",
    "\n",
    "print(r2(y_test, GBR_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16c212f",
   "metadata": {},
   "source": [
    "**Создаём финальную модель**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c158f42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(n_estimators=500)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBR_f = GradientBoostingRegressor(loss='squared_error', max_depth=3, n_estimators=500)\n",
    "GBR_f.fit(X_train_num, y_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574c8d6",
   "metadata": {},
   "source": [
    "**Предсказываем значения**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f73997b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46.47667738, 62.65971334, 55.80184399, 81.59091181, 66.81512507,\n",
       "       69.28727413, 58.35030745, 70.77006361, 74.91741215, 50.54747477,\n",
       "       99.02532598, 91.31237777, 65.58765963, 63.34271245, 94.81910185,\n",
       "       93.85861137, 55.38032847, 80.04654652, 68.77165537, 63.60935839,\n",
       "       68.96765697, 78.99527698, 49.32083326, 94.27245232, 85.96086331,\n",
       "       68.05005093, 42.67008806, 60.01917146, 78.27127082, 64.65173348,\n",
       "       53.76178707, 66.65125675, 74.49528108, 91.95068748, 48.84166321,\n",
       "       74.46045795, 76.728359  , 78.76390285, 91.16190249, 46.47477351,\n",
       "       48.2853529 , 70.73677452, 69.2722212 , 72.16348124, 51.96624302,\n",
       "       68.61482034, 58.88256598, 69.05162737, 58.54026435, 90.77126213,\n",
       "       61.73313806, 41.45862201, 55.63450481, 53.5756538 , 69.49210333,\n",
       "       39.99288148, 76.65046008, 66.65783136, 48.0047105 , 92.91176698,\n",
       "       83.81500606, 75.4860774 , 52.298191  , 91.95680493, 49.25705677,\n",
       "       60.55923191, 59.0233571 , 67.97699337, 65.31084367, 60.02779404,\n",
       "       56.68034113, 41.49648488, 59.67644274, 83.33362534, 53.00126271,\n",
       "       52.32043769, 53.13660259, 47.53319218, 80.35598278, 77.27866144,\n",
       "       58.0780195 , 61.37795467, 66.116215  , 77.5844722 , 64.01600144,\n",
       "       59.79356548, 47.54230317, 61.54920288, 59.91269062, 54.946234  ,\n",
       "       56.64624311, 80.04654652, 48.13994119, 61.58184864, 60.78799795,\n",
       "       77.66169488, 70.40597812, 75.72869304, 61.0694114 , 89.11503217,\n",
       "       59.53173788, 68.10913278, 55.32285389, 69.93317616, 86.20570995,\n",
       "       70.08004938, 56.519101  , 91.02533861, 78.62734547, 49.44164786,\n",
       "       90.67421725, 59.26428142, 47.81350392, 63.92881765, 79.569513  ,\n",
       "       80.31698027, 66.92173516, 85.26696407, 70.73677452, 48.73291396,\n",
       "       92.73719874, 76.15331191, 55.51978739, 60.46751438, 57.77012742,\n",
       "       81.56454049, 53.00126271, 78.86715056, 72.35873672, 74.78307602,\n",
       "       80.24507558, 54.73054586, 60.02186499, 72.40915689, 71.25471947,\n",
       "       53.76562205, 84.79021061, 62.07028401, 42.86886421, 60.19791934,\n",
       "       93.40406162, 71.94826456, 82.70960116, 75.98548964, 69.02468127,\n",
       "       75.03872421, 57.17554787, 67.32447209, 61.78182488, 49.00439349,\n",
       "       47.19961957, 57.23504261, 59.26428142, 56.67158958, 66.26675976,\n",
       "       41.70357067, 86.0980751 , 63.80880459, 47.81350392, 40.714405  ,\n",
       "       94.45699671, 69.22687568, 73.89722826, 52.4243648 , 61.83267282,\n",
       "       54.32597431, 73.79086689, 66.65125675, 73.80093064, 78.63899276,\n",
       "       72.94338742, 40.37642168, 70.14715032, 60.89453479, 72.61386526,\n",
       "       90.0082816 , 77.86413503, 60.8548508 , 71.69014886, 73.50371081,\n",
       "       69.51961551, 65.10981256, 55.78095139, 75.25373857, 68.99805457,\n",
       "       90.77126213, 56.89054628, 49.91380603, 55.29993472, 70.09442876,\n",
       "       44.32339071, 79.61239925, 40.9473319 , 78.74706668, 85.25045835,\n",
       "       82.31899664, 56.68034113, 49.33133249, 47.54230317, 88.8965039 ,\n",
       "       91.95068748, 53.4582349 , 66.25660307, 76.57590096, 69.31417722,\n",
       "       78.44323515, 67.32447209, 50.7895799 , 66.90836854, 62.5005523 ,\n",
       "       84.04830186, 62.56117659, 58.67657176, 71.73481701, 63.24833496,\n",
       "       59.12324049, 54.24275159, 60.02186499, 84.7142998 , 89.30135265,\n",
       "       80.09110151, 57.03674202, 40.37642168, 71.68102712, 56.16719599,\n",
       "       54.946234  , 84.49005098, 60.66304321, 69.26454584, 77.13436003,\n",
       "       76.58229225, 80.94854282, 66.74551393, 83.48305197, 47.95029235,\n",
       "       62.21095762, 43.1969766 , 43.6472873 , 79.82743491, 61.84475339,\n",
       "       55.36812629, 67.86797568, 53.86451838, 60.69635769, 67.54149482,\n",
       "       70.33698222, 83.54639414, 70.09601025, 92.36738661, 66.04640038,\n",
       "       93.05289434, 61.78182488, 48.13994119, 99.20443323, 75.18787252,\n",
       "       63.77324149, 79.76053845, 78.07855585, 53.22278321, 93.05289434,\n",
       "       55.39009357, 70.22235583, 76.3461393 , 54.69532179, 92.50473745,\n",
       "       47.36666493, 47.86922752, 55.91413181, 54.35789826, 87.72700054,\n",
       "       87.89041955, 56.63647375, 40.44605313, 56.29142054, 66.4844301 ,\n",
       "       58.78996213, 56.17364131, 49.97216277, 48.73291396, 66.53682692,\n",
       "       90.53222037, 67.84520054, 78.50363358, 64.85682492, 72.19193487,\n",
       "       62.21095762, 85.43100195, 38.45238803, 94.81910185, 94.27245232,\n",
       "       66.30524054, 56.18479142, 54.76168064, 89.01799447, 82.02740692,\n",
       "       94.73047082, 85.25045835, 55.3391358 , 81.56454049, 57.91449123,\n",
       "       55.63450481, 71.66722751, 65.96452438, 67.24775865, 87.2338823 ,\n",
       "       88.81992696, 40.714405  , 77.00546023, 80.51372035, 83.78013669,\n",
       "       91.95068748, 81.92687921, 55.00874212, 57.82234123, 47.81756981,\n",
       "       47.48666742, 53.88483349, 67.87635853, 76.82946286, 81.97139444,\n",
       "       96.38557812, 40.20032075, 52.18354845, 49.42151262, 61.01656955,\n",
       "       51.88279743, 79.67166476, 58.78996213, 54.98941037, 63.9446216 ,\n",
       "       78.31420219, 90.6536162 , 78.71180034, 49.56632616, 73.47370886])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = GBR_f.predict(test_num)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb07714",
   "metadata": {},
   "source": [
    "**Сверяем предсказанные значения с ответом**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a369307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posttest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   posttest\n",
       "0      50.0\n",
       "1      66.0\n",
       "2      58.0\n",
       "3      85.0\n",
       "4      63.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = pd.read_csv(\"answers_2.csv\")\n",
    "answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5c57973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9613642280429607\n"
     ]
    }
   ],
   "source": [
    "print(r2(answers, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38027147",
   "metadata": {},
   "source": [
    "### eXtreme Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b86e40",
   "metadata": {},
   "source": [
    "XGBoost — это оптимизированная библиотека градиентного бустинга, разработанная для обеспечения высокой *эффективности, гибкости и портативности*. Он реализует алгоритмы машинного обучения в рамках платформы Gradient Boosting. При этом XGBoost — это не какой-то новый уникальный алгоритм, а просто крайне эффективная реализация классического GBM с некоторыми дополнительными улучшениями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a791e8be",
   "metadata": {},
   "source": [
    "**Системная оптимизация:**\n",
    "<br>***1. Параллелизация.*** В XGBoost построение деревьев основано на параллелизации. Это возможно благодаря взаимозаменяемой природе циклов, используемых для построения базы для обучения: внешний цикл перечисляет листья деревьев, внутренний цикл вычисляет признаки. Нахождение цикла внутри другого мешает параллелизировать алгоритм, так как внешний цикл не может начать своё выполнение, если внутренний ещё не закончил свою работу. Поэтому для улучшения времени работы порядок циклов меняется: инициализация проходит при считывании данных, затем выполняется сортировка, использующая параллельные потоки. Эта замена улучшает производительность алгоритма, распределяя вычисления по потокам.\n",
    "<br>***2. Отсечение ветвей дерева.*** В фреймворке GBM критерий остановки для разбиения дерева зависит от критерия отрицательной потери в точке разбиения. XGBoost использует параметр максимальной глубины max_depth вместо этого критерия и начинает обратное отсечение, то есть он находит разделения до заданной максимальной глубины, а затем начинает обрезать дерево и удалять разделения, после которых нет положительных результатов. Этот подход значительно улучшает вычислительную производительность. \n",
    "<br>***3. Аппаратная оптимизация.*** Алгоритм был разработан таким образом, чтобы он оптимально использовал аппаратные ресурсы. Это достигается путём создания внутренних буферов в каждом потоке для хранения статистики градиента. Дальнейшие улучшения, как, например, вычисления вне ядра, позволяют работать с большими наборами данных, которые не помещаются в памяти компьютера.\n",
    "<br><br>**Улучшения алгоритма:**\n",
    "<br>***1. Регуляризация.*** Он штрафует сложные модели, используя как регуляризацию L1, так и регуляризацию L2, для того чтобы избежать переобучения.\n",
    "<br>***2. Работа с разреженными данными.*** Алгоритм упрощает работу с разреженными данными, в процессе обучения заполняя пропущенные значения в зависимости от значения функции потерь.\n",
    "<br>***3. Кросс-валидация.**** Алгоритм использует свой собственный метод кросс-валидации на каждой итерации. То есть, нам не нужно отдельно программировать этот поиск и определять количество итераций бустинга для каждого запуска."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a9e9bb",
   "metadata": {},
   "source": [
    "#### Гиперпараметры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c1aa65",
   "metadata": {},
   "source": [
    "Основные:\n",
    "<br>**n_estimators**: число деревьев.\n",
    "<br>**eta**: размер шага. Предотвращает переобучение.\n",
    "<br>**gamma**: минимальное изменение значения loss функции для разделения листа на поддеревья.\n",
    "<br>**max_depth**: максимальная глубина дерева.\n",
    "<br>**lambda/alpha**: L2/L1 регуляризация.\n",
    "\n",
    "Подробнее: https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7bcb6c",
   "metadata": {},
   "source": [
    "#### Пример использования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493e5b7d",
   "metadata": {},
   "source": [
    "##### Строим модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9dd09f",
   "metadata": {},
   "source": [
    "**Создаём нашу модель**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3737120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_num, y_train_num, test_size=0.3, random_state=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor(n_estimators=200, max_depth=3, random_state=1, reg_lambda=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a96690",
   "metadata": {},
   "source": [
    "**Учим модель**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae977a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9420691355806551\n"
     ]
    }
   ],
   "source": [
    "XGB.fit(X_train, y_train)\n",
    "XGB_predict = XGB.predict(X_test)\n",
    "\n",
    "print(r2(y_test, XGB_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a3ee4f",
   "metadata": {},
   "source": [
    "**Создаём финальную модель**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15f5a7c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=200, n_jobs=4,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=1, reg_alpha=0,\n",
       "             reg_lambda=0.7, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_f = xgb.XGBRegressor(n_estimators=200, max_depth=3, random_state=1, reg_lambda=0.7)\n",
    "XGB_f.fit(X_train_num, y_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6430f8",
   "metadata": {},
   "source": [
    "**Предсказываем значения**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "925f102d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46.281734, 62.782825, 54.64514 , 82.202896, 68.10658 , 69.433044,\n",
       "       58.501225, 71.41305 , 75.20048 , 51.304615, 98.77448 , 91.29235 ,\n",
       "       66.469124, 62.80782 , 95.27786 , 91.30527 , 55.65014 , 78.81028 ,\n",
       "       68.725624, 62.62252 , 69.227   , 78.382835, 49.45116 , 93.77728 ,\n",
       "       86.50311 , 68.24686 , 43.03709 , 59.784435, 78.25263 , 64.04166 ,\n",
       "       54.22354 , 66.47311 , 74.511696, 92.74828 , 48.791153, 74.43759 ,\n",
       "       76.539314, 78.184   , 90.54505 , 46.111626, 47.924698, 70.53032 ,\n",
       "       69.16572 , 71.93129 , 51.821064, 68.789856, 59.82017 , 69.52326 ,\n",
       "       58.87929 , 91.60464 , 61.438553, 41.537426, 55.821045, 54.12288 ,\n",
       "       69.360405, 39.792664, 77.40532 , 66.47153 , 49.19908 , 93.02208 ,\n",
       "       84.18282 , 75.03617 , 52.315784, 91.27929 , 49.16922 , 60.653034,\n",
       "       59.055946, 68.51423 , 64.38348 , 59.912582, 57.030296, 41.51461 ,\n",
       "       60.075718, 83.89314 , 53.05998 , 52.8754  , 53.462875, 47.210175,\n",
       "       79.44333 , 76.32882 , 57.64832 , 60.89465 , 65.542305, 76.22519 ,\n",
       "       64.67323 , 60.59573 , 47.17105 , 59.882156, 60.351242, 54.9735  ,\n",
       "       56.634624, 78.81028 , 48.358067, 61.781876, 60.10437 , 77.1959  ,\n",
       "       70.79523 , 75.03716 , 60.97936 , 89.79725 , 58.748352, 68.17075 ,\n",
       "       55.54769 , 70.108185, 86.27672 , 69.861176, 56.535934, 90.399895,\n",
       "       78.003235, 48.81062 , 91.25751 , 58.740574, 47.981155, 62.69704 ,\n",
       "       79.121994, 80.30206 , 66.49049 , 85.15556 , 70.53032 , 48.99042 ,\n",
       "       92.85784 , 75.1477  , 54.847004, 60.4302  , 58.092514, 81.85491 ,\n",
       "       53.05998 , 78.990685, 73.20723 , 74.83396 , 80.5086  , 54.889503,\n",
       "       60.017345, 71.78089 , 71.285034, 53.98791 , 86.2165  , 61.395412,\n",
       "       43.072296, 60.350136, 93.438896, 72.01903 , 82.89792 , 76.348495,\n",
       "       69.122696, 75.399414, 56.48909 , 67.99257 , 60.602856, 49.72189 ,\n",
       "       47.301617, 56.87237 , 58.740574, 56.148155, 65.40332 , 41.558075,\n",
       "       86.38946 , 63.6085  , 47.981155, 40.85905 , 95.37237 , 69.20459 ,\n",
       "       74.14334 , 53.06385 , 62.685623, 53.151222, 73.65567 , 66.47311 ,\n",
       "       74.47182 , 77.623405, 73.0443  , 40.259716, 70.15017 , 59.971478,\n",
       "       72.390495, 91.0612  , 77.790565, 60.848328, 71.46815 , 73.68668 ,\n",
       "       69.884964, 64.65964 , 55.416805, 75.40775 , 68.4022  , 91.60464 ,\n",
       "       57.2475  , 49.844444, 55.279144, 70.98371 , 44.231594, 79.46828 ,\n",
       "       40.983864, 78.51044 , 84.780525, 82.77956 , 57.030296, 48.69341 ,\n",
       "       47.17105 , 88.12471 , 92.74828 , 53.988617, 65.61114 , 77.3586  ,\n",
       "       69.64106 , 78.50817 , 67.99257 , 50.60453 , 67.56141 , 62.471245,\n",
       "       83.36229 , 62.422318, 58.445694, 72.40504 , 62.618538, 59.20873 ,\n",
       "       55.34366 , 60.017345, 85.35541 , 84.88213 , 79.68245 , 56.93811 ,\n",
       "       40.259716, 71.04337 , 55.698532, 54.9735  , 84.31091 , 60.509956,\n",
       "       70.79806 , 76.998024, 75.84476 , 81.07745 , 67.26803 , 81.585526,\n",
       "       48.235176, 62.254593, 43.26134 , 43.801414, 79.16917 , 61.397114,\n",
       "       55.874756, 68.480606, 54.164356, 59.742847, 67.28388 , 70.34952 ,\n",
       "       83.36229 , 69.6804  , 91.99367 , 66.13426 , 93.03916 , 60.602856,\n",
       "       48.358067, 99.26834 , 75.36452 , 63.64001 , 79.90612 , 76.70646 ,\n",
       "       53.170006, 93.03916 , 54.889126, 72.131996, 76.22275 , 54.4606  ,\n",
       "       92.39819 , 47.057278, 48.278774, 55.14128 , 54.49755 , 88.66428 ,\n",
       "       88.879   , 55.787743, 40.40307 , 56.398926, 67.19486 , 59.039845,\n",
       "       56.91672 , 50.47514 , 48.99042 , 66.106476, 90.0096  , 68.65785 ,\n",
       "       78.950966, 64.87301 , 71.890594, 62.254593, 85.13275 , 36.457645,\n",
       "       95.27786 , 93.77728 , 63.569695, 55.788193, 54.25835 , 86.71289 ,\n",
       "       82.32805 , 93.486694, 84.780525, 54.809914, 81.85491 , 58.206596,\n",
       "       55.821045, 71.63151 , 66.12299 , 67.06153 , 87.6333  , 88.6158  ,\n",
       "       40.85905 , 78.18414 , 80.40762 , 83.71316 , 92.74828 , 80.822914,\n",
       "       54.98746 , 58.427513, 47.74744 , 47.853954, 53.831177, 68.55416 ,\n",
       "       77.17053 , 82.120445, 94.54276 , 40.275   , 51.203125, 49.668877,\n",
       "       60.36838 , 52.17679 , 79.66376 , 59.039845, 54.682312, 64.225624,\n",
       "       79.013985, 89.44973 , 78.95989 , 49.896484, 73.26056 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = XGB_f.predict(test_num)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35d8b52",
   "metadata": {},
   "source": [
    "**Сверяем предсказанные значения с ответом**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d9981b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posttest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   posttest\n",
       "0      50.0\n",
       "1      66.0\n",
       "2      58.0\n",
       "3      85.0\n",
       "4      63.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = pd.read_csv(\"answers_2.csv\")\n",
    "answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31c07cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9604606591357113\n"
     ]
    }
   ],
   "source": [
    "print(r2(answers, y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
